Response to reviewers re: Bjorn et al.
=====

Bjorn asked Barry to respond to reviewer 2's point #3:

> The dn/ds analysis, while attractive, may be unreliable.
> There are two reasons for this.
> The first, and probably the most important and potentially worrisome, is that
> dn/ds assumes fixation of SNPs among divergent taxa.

This is true.
I vote we stop calling it dN/dS and start talking about how it's conceptually
similar, but not theoretically the same.

> It does not work reliably, as Kryazhimskiy and Plotkin have shown in their
> PLoS Genetics paper from 2008, for transient variation.
> Although K&P’s paper focused on the issue of polymorphism within a
> population, as it sweeps to fixation for example, it seems to me that the
> vulnerabilities of dn/ds are the same for the situation described in the
> current paper.

Do we cite this paper?

> The authors argue here that the main selective process at work in these
> fields is sorting among taxa.
> Sorting and sweeping, especially in predominantly asexual taxa, amount to the
> same thing from the perspective of selection.

YES!

> It is notable that polymorphism underestimates the strength of purifying
> selection compared to fixation, and the values (guesstimating from K&P’s
> figure 1) are not far off what Ostman and colleagues have measured.

What does the reviewer mean by this?
Do K&P say that it biases the estimates of omega towards a _particular_ value?

> While the authors could probably argue that the relevant comparisons are
> across the different sampling sites – and the pattern they observe is
> unlikely to be derived from poor performance of the dn/ds estimator

We do argue this.
Is it explicit?

> – at the
> bare minimum the authors need to justify the use of dn/ds in the face of its
> known poor performance for segregating variation.

I agree..._if_ we're trying to estimate omega.
If our goal is something theoretically different, than we're just proposing
a single index for the strength of ecological filtering.
This is similar to Jeraldo et al. 2012 (although I think their approach is
very flawed).

> I do not think anyone has a good handle on whether the bias is consistent in
> a manner that still allows strong inference.

This is a valid criticism, even if we're just using the ratio as an index
of species filtering.
This encapsulates why I think validation across systems (and
including simulation data) is important.

> The second reason is common to all dn/ds analyses: synonymous sites may not
> be neutral.
> The non-neutrality of synonymous mutations was recently demonstrated directly
> by Bailey et al (Nature Comms 2014) who showed that synonymous mutations had
> beneficial fitness effects as large as any non-synonymous mutation.
> The issue is a hard one to address until we know more about the distribution
> of fitness effects among synonymous mutations, but it is worth keeping in
> mind as a caveat anyway.

Yep.
I agree.
Something we should mention in our discussion.


## Other comments ##

Can we do the neutral model stuff with the nirK surveys instead of 16S?
